# Сделано 
1. Выгружено в общую папку и на гитхаб 90 тыс размеченных фраз сервисом Арсенкин
2. Результаты работы с BOW и обучаемым эмбедингом:
- результат на датасете 70 тыс 80+% http://joxi.ru/vAWebzyfqj7J0m
- тестирование модели на новой семантике "путешествия" дает снижение результатов сравнимое с падением BOW - до 40-70% http://joxi.ru/Y2LDMzkIQwRKa2

# Вывод: 
- Обучение НС классификации ключей на любом ограниченном наборе слов не будет работать при расширении семантики
- Возможно результаты будут выше с предобученным эмбедингом на всем массиве русских слов. Тогда НС сможет учитывать смысл слов и их связь а не только структуру запросов и ограниченный словарь
- Возможна схема дообучения на каждом новом наборе семантики. В этом случае эффективность BOW выше чем эмбединга (90% против 80%)

# Результаты экспериментов:
https://colab.research.google.com/drive/1yhZlHgcLaqEpFlD6ojfNustp53spMDhN#scrollTo=JoXz5Lw09ewq
https://colab.research.google.com/drive/1SmmqLZALqWFdzJm7023fyBftvsDi5hir#scrollTo=A5S3YUDNn1ng
